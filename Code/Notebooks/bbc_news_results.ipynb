{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2670"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>message_id</th>\n",
       "      <th>message</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1717</td>\n",
       "      <td>lee to create new film superhero comic book ve...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>471</td>\n",
       "      <td>german growth goes into reverse germany s econ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>278</td>\n",
       "      <td>mps issued with blackberry threat mps will be ...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1436</td>\n",
       "      <td>hamm bows out for us women s football legend m...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>iraq advice claim sparks new row the tories sa...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>440</th>\n",
       "      <td>272</td>\n",
       "      <td>china now top trader with japan china overtook...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>441</th>\n",
       "      <td>1270</td>\n",
       "      <td>pc ownership to  double by 2010  the number of...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>442</th>\n",
       "      <td>1858</td>\n",
       "      <td>bollywood dvd fraudster is jailed a major dist...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>443</th>\n",
       "      <td>1617</td>\n",
       "      <td>id theft surge hits us consumers almost a quar...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>444</th>\n",
       "      <td>1872</td>\n",
       "      <td>bell set for england debut bath prop duncan be...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>445 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     message_id                                            message  label\n",
       "0          1717  lee to create new film superhero comic book ve...      3\n",
       "1           471  german growth goes into reverse germany s econ...      1\n",
       "2           278  mps issued with blackberry threat mps will be ...      4\n",
       "3          1436  hamm bows out for us women s football legend m...      2\n",
       "4             5  iraq advice claim sparks new row the tories sa...      4\n",
       "..          ...                                                ...    ...\n",
       "440         272  china now top trader with japan china overtook...      1\n",
       "441        1270  pc ownership to  double by 2010  the number of...      0\n",
       "442        1858  bollywood dvd fraudster is jailed a major dist...      3\n",
       "443        1617  id theft surge hits us consumers almost a quar...      1\n",
       "444        1872  bell set for england debut bath prop duncan be...      2\n",
       "\n",
       "[445 rows x 3 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1780"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_distribution[:round(len(train_distribution) * 0.80)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(445, 445)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test), len(test_retained)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2136"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(445, 445, 445)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test_distribution), len(test), len(test_retained)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bbc_news\n",
      "CTM\n",
      "Run: 1\n",
      "Linear model score: 0.7865168539325843\n",
      "Linear model RMSE: 0.5660976545086227\n",
      "Linear model R2: 0.8136061685141058\n",
      "Linear model MAE: 0.35976824045254524\n",
      "\n",
      "Logistic model: 0.946067415730337\n",
      "Rf model: nan\n",
      "Old Logistic model: 0.907865168539326\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# bbc_news\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import csv\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LinearRegression, LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import sklearn\n",
    "from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error\n",
    "\n",
    "dataset = 'bbc_news' # folder and dataset name\n",
    "# cols = ['gender', 'age', 'politics'] # outcome columns\n",
    "cols = ['label_x'] # outcome columns\n",
    "outcome = 'label'\n",
    "\n",
    "logit = True\n",
    "\n",
    "df = pd.read_csv(\"data/\" + dataset + \".csv\")\n",
    "\n",
    "print(dataset)\n",
    "\n",
    "# for model in ['GensimLDA', 'BERTopic', 'NMF', 'Mallet_LDA', 'CTM']:\n",
    "for model in ['CTM']:\n",
    "    print(model)\n",
    "    scores = []\n",
    "    scores_logit = []\n",
    "    scores_rf = []\n",
    "    scores_old = []\n",
    "\n",
    "    rmses = []\n",
    "    r2s = []\n",
    "    maes = []\n",
    "\n",
    "    for run in range(1, 2):\n",
    "\n",
    "        print(\"Run: \" + str(run))\n",
    "\n",
    "        # loading in distributions that were saved during topic extraction\n",
    "        test_distribution = pickle.load(open(dataset + '/' + model + '/run_' + str(run) + '/' + model + '_topic_distribution_test.pkl', 'rb'))\n",
    "        test = pickle.load(open(dataset + '/' + model + '/run_' + str(run) + '/test.pkl', 'rb'))\n",
    "        test_retained = pickle.load(open(dataset + '/' + model + '/run_' + str(run) + '/test_retained.pkl', 'rb'))\n",
    "\n",
    "        if model == 'CTM':\n",
    "            train_distribution = pickle.load(open(dataset + '/' + model + '/run_' + str(run) + '/' + model + '_topic_distribution_train.pkl', 'rb'))\n",
    "            train_distribution = train_distribution[:round(len(train_distribution) * 0.80)]\n",
    "        else:\n",
    "            train_distribution = pickle.load(open(dataset + '/' + model + '/run_' + str(run) + '/' + model + '_topic_distribution_train.pkl', 'rb'))\n",
    "        train = pickle.load(open(dataset + '/' + model + '/run_' + str(run) + '/train.pkl', 'rb'))\n",
    "        train_retained = pickle.load(open(dataset + '/' + model + '/run_' + str(run) + '/train_retained.pkl', 'rb'))\n",
    "\n",
    "        topics = []\n",
    "        with open(dataset + '/' + model + '/run_' + str(run) + '/' + 'topics_100.txt', 'r') as f:\n",
    "            reader = csv.reader(f)\n",
    "            for row in reader:\n",
    "                topic_list = [item.strip() for item in row if item.strip()]\n",
    "                topics.append(topic_list)\n",
    "\n",
    "        temp = pd.concat([train, test]).reset_index(drop=True) # concatenating train and test datasets\n",
    "        distribution = np.concatenate([train_distribution, test_distribution]) # concatenating train and test distributions\n",
    "\n",
    "        merged = pd.merge(temp, df, how='inner', left_on = 'message_id', right_on = 'Unnamed: 0')[['message_id', 'message_x'] + cols]\n",
    "        merged.columns = ['message_id', 'message', 'label']\n",
    "\n",
    "        X = distribution\n",
    "        y = merged[outcome].reset_index(drop=True) # the outcome we care about\n",
    "\n",
    "        # # 80-20 split --> didn't use train-test-split function since its already shuffled\n",
    "        X_train = X[:round(0.80 * len(X))]\n",
    "        X_test = X[round(0.80 * len(X)):]\n",
    "\n",
    "        y_train = y[:round(0.80 * len(X))]\n",
    "        y_test = y[round(0.80 * len(X)):]\n",
    "\n",
    "        lr_model = LinearRegression().fit(X_train, y_train) \n",
    "        y_pred_test = lr_model.predict(X_test)\n",
    "\n",
    "        pred_rounded = []\n",
    "\n",
    "        for i in np.round(y_pred_test):\n",
    "            min = y_test.min()\n",
    "            max = y_test.max()\n",
    "            if i >= min and i <= max:\n",
    "                pred_rounded.append(i)\n",
    "            elif i > max:\n",
    "                pred_rounded.append(max)\n",
    "            else:\n",
    "                pred_rounded.append(min)\n",
    "\n",
    "        score = sklearn.metrics.accuracy_score(pred_rounded, list(y_test))\n",
    "        scores.append(score)\n",
    "\n",
    "        rmse_test = mean_squared_error(y_true=y_test, y_pred=y_pred_test, squared=False)\n",
    "        r2_test = r2_score(y_true=y_test, y_pred=y_pred_test)\n",
    "        mae_test = mean_absolute_error(y_true=y_test, y_pred=y_pred_test)\n",
    "\n",
    "        rmses.append(rmse_test)\n",
    "        r2s.append(r2_test)\n",
    "        maes.append(mae_test)\n",
    "\n",
    "        logit_model = LogisticRegression().fit(X_train, y_train)\n",
    "        pred_logit = logit_model.predict(X_test)\n",
    "        score_logit = sklearn.metrics.accuracy_score(pred_logit, list(y_test))\n",
    "        scores_logit.append(score_logit)\n",
    "\n",
    "        # rf = RandomForestClassifier(random_state = 42).fit(X_train, y_train)\n",
    "        # pred_rf = rf.predict(X_test)\n",
    "        # score_rf = sklearn.metrics.accuracy_score(pred_rf, list(y_test))\n",
    "        # scores_rf.append(score_rf)\n",
    "\n",
    "        dummy_train = pd.get_dummies(train['label'], dtype=int)\n",
    "        dummy_test = pd.get_dummies(test['label'], dtype=int)\n",
    "        dummy_train.columns = [\"label \" + str(i) for i in range(len(dummy_train.columns))]\n",
    "        dummy_test.columns = [\"label \" + str(i) for i in range(len(dummy_test.columns))]\n",
    "\n",
    "        accuracies = []\n",
    "        r2s_old = []\n",
    "        for i, label_col in enumerate(list(dummy_train)):\n",
    "            lr_model_old = LogisticRegression().fit(X_train, dummy_train[label_col])\n",
    "            accuracies.append(lr_model_old.score(X_test, dummy_test[label_col]))\n",
    "            r2s_old.append(r2_score(dummy_test[label_col], lr_model_old.predict(X_test)))\n",
    "        \n",
    "        accuracies = [np.mean(accuracies)] + accuracies + [np.mean(r2s_old)]\n",
    "        scores_old.append(accuracies[0])\n",
    "        \n",
    "    print(\"Linear model score: \" + str(np.mean(scores)))\n",
    "    print(\"Linear model RMSE: \" + str(np.mean(rmses)))\n",
    "    print(\"Linear model R2: \" + str(np.mean(r2s)))\n",
    "    print(\"Linear model MAE: \" + str(np.mean(maes)))\n",
    "    print()\n",
    "    print(\"Logistic model: \" + str(np.mean(scores_logit)))\n",
    "    print(\"Rf model: \" + str(np.mean(scores_rf)))\n",
    "    print(\"Old Logistic model: \" + str(np.mean(scores_old)))\n",
    "    print()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "BERTopic_1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.1.undefined"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
