{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "# fb = pd.read_csv('fb.csv')\n",
    "# twitter = pd.read_csv('twitter.csv')\n",
    "# qualtrics = pd.read_csv('qualtrics.csv')\n",
    "\n",
    "qualtrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([4., 5., 1., 7., 6., 2., 3.])"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "round(twitter['politics']).unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fb\n",
      "GensimLDA\n",
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Python(21290) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n",
      "Python(21292) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n",
      "Python(21294) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n",
      "Python(21296) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n",
      "Python(21298) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n",
      "Python(21300) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n",
      "Python(21303) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import abc\n",
    "import re\n",
    "import itertools\n",
    "from gensim.corpora.dictionary import Dictionary\n",
    "from gensim.models.coherencemodel import CoherenceModel\n",
    "import csv\n",
    "\n",
    "def proportion_unique_words(topics, topk=10):\n",
    "    if topk > len(topics[0]):\n",
    "        raise Exception('Words in topics are less than '+str(topk))\n",
    "    else:\n",
    "        unique_words = set()\n",
    "        for topic in topics:\n",
    "            unique_words = unique_words.union(set(topic[:topk]))\n",
    "        puw = len(unique_words) / (topk * len(topics))\n",
    "        return puw\n",
    "\n",
    "class Coherence(abc.ABC):\n",
    "    def __init__(self, topics, texts):\n",
    "        self.topics = topics\n",
    "        self.texts = texts\n",
    "        self.dictionary = Dictionary(self.texts)\n",
    "\n",
    "    @abc.abstractmethod\n",
    "    def score(self):\n",
    "        pass\n",
    "\n",
    "class CoherenceNPMI(Coherence):\n",
    "    def __init__(self, topics, texts):\n",
    "        super().__init__(topics, texts)\n",
    "\n",
    "    def score(self, topk=10, per_topic=False):\n",
    "        if topk > len(self.topics[0]):\n",
    "            raise Exception('Words in topics are less than topk')\n",
    "        else:\n",
    "            npmi = CoherenceModel(\n",
    "                topics=self.topics, texts=self.texts,\n",
    "                dictionary=self.dictionary,\n",
    "                coherence='c_npmi', topn=topk)\n",
    "            if per_topic:\n",
    "                return npmi.get_coherence_per_topic()\n",
    "            else:\n",
    "                return npmi.get_coherence()\n",
    "\n",
    "\n",
    "\n",
    "dataset_model_scores = {}\n",
    "\n",
    "# for dataset in ['yelp_reviews', 'fb', 'twitter', 'qualtrics', '20_newsgroup']:\n",
    "for dataset in ['fb']:\n",
    "    print(dataset)\n",
    "\n",
    "    df = pd.read_csv(dataset + \".csv\")\n",
    "    if dataset == 'amazon':\n",
    "        documents = [line.strip() for line in (df['text']) if not isinstance(line, float)]\n",
    "    else:\n",
    "        documents = [line.strip() for line in (df['message']) if not isinstance(line, float)]\n",
    "\n",
    "    model_scores = {} # tuple of model : (avg diversity, avg coherence)\n",
    "\n",
    "    for model in ['GensimLDA', 'Mallet_LDA', 'CTM', 'BERTopic', 'NMF']:\n",
    "        print(model)\n",
    "\n",
    "        diversities = []\n",
    "        coherences = []\n",
    "\n",
    "        for run in range(1, 6):\n",
    "            print(run)\n",
    "\n",
    "            topics = []\n",
    "            with open(dataset + '/' + model + '/run_' + str(run) + '/' + 'topics_100.txt', 'r') as f:\n",
    "                reader = csv.reader(f)\n",
    "                for row in reader:\n",
    "                    topic_list = [item.strip() for item in row if item.strip()]\n",
    "                    topics.append(topic_list)\n",
    "\n",
    "            warnings.filterwarnings('ignore')\n",
    "            topic_diversity = proportion_unique_words(topics)\n",
    "            tokenizer = lambda s: re.findall( '\\w+', s.lower() )\n",
    "            texts = [tokenizer(t) for t in  documents]\n",
    "            coherence = CoherenceNPMI(texts=texts, topics=topics).score()\n",
    "\n",
    "            diversities.append(topic_diversity)\n",
    "            coherences.append(coherence)\n",
    "        \n",
    "        model_scores[model] = (np.mean(diversities), np.mean(coherences))\n",
    "        print(np.mean(diversities))\n",
    "        print(np.mean(coherences))\n",
    "    \n",
    "    dataset_model_scores[dataset] = model_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GensimLDA\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "0.489\n",
      "-0.048823966202612354\n"
     ]
    }
   ],
   "source": [
    "dataset = 'bbc_news'\n",
    "model = 'GensimLDA'\n",
    "\n",
    "df = pd.read_csv(dataset + \".csv\")\n",
    "documents = [line.strip() for line in (df['message']) if not isinstance(line, float)]\n",
    "\n",
    "print(model)\n",
    "\n",
    "diversities = []\n",
    "coherences = []\n",
    "\n",
    "for run in range(1, 6):\n",
    "    print(run)\n",
    "\n",
    "    topics = []\n",
    "    with open(dataset + '/' + model + '/run_' + str(run) + '/' + 'topics_100.txt', 'r') as f:\n",
    "        reader = csv.reader(f)\n",
    "        for row in reader:\n",
    "            topic_list = [item.strip() for item in row if item.strip()]\n",
    "            topics.append(topic_list)\n",
    "\n",
    "    warnings.filterwarnings('ignore')\n",
    "    topic_diversity = proportion_unique_words(topics)\n",
    "    tokenizer = lambda s: re.findall( '\\w+', s.lower() )\n",
    "    texts = [tokenizer(t) for t in  documents]\n",
    "    coherence = CoherenceNPMI(texts=texts, topics=topics).score()\n",
    "\n",
    "    diversities.append(topic_diversity)\n",
    "    coherences.append(coherence)\n",
    "\n",
    "print(np.mean(diversities))\n",
    "print(np.mean(coherences))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
